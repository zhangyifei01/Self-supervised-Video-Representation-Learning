# Self-supervised-Video-Representation-Learning 
## 自监督视频表示学习

**[ Updating ...... ]**

Self-supervised video representation learning aims to learn general representations from video datasets to initialize downstream video tasks. 

Image-level self-supervised learning methods can be found in this [repository](https://github.com/zhangyifei01/Unsupervised-Visual-Representation-Learning).

We list related papers from conferences and journals such as **[CVPR](https://openaccess.thecvf.com/menu)**, **[ICCV](https://openaccess.thecvf.com/menu)**, **[ECCV](https://www.ecva.net/)**, **[ICLR](https://openreview.net/group?id=ICLR.cc&referrer=%5BHomepage%5D(%2F))**, **[ICML](https://proceedings.mlr.press/)**, **[NeurIPS](https://nips.cc/)**, **[AAAI](https://aaai.org/Library/conferences-library.php)**, **[TPAMI](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)**, **TIP**, **TNNLS**, **TCSVT**, **TMM** etc.

**Key words:** Unsupervised learning, self-supervised learning, representation learning, pre-training, transfer learning, contrastive learning, pretext task

**关键词：** 无监督学习，自监督学习，表示学习，预训练，迁移学习，对比学习，借口（代理）任务

## 2022

***
- TransRank: Self-Supervised Video Representation Learning via Ranking-Based Transformation Recognition (**TransRank** - <font color="#dd0000">**CVPR**22 Oral</font>) [[paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_TransRank_Self-Supervised_Video_Representation_Learning_via_Ranking-Based_Transformation_Recognition_CVPR_2022_paper.pdf) [[code]](https://github.com/kennymckormick/TransRank) [[supp]](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Duan_TransRank_Self-Supervised_Video_CVPR_2022_supplemental.pdf)
    <details> 
    <summary><font size=2>More Info</font></summary>
    <font color=Gray> <b>· · Author(s)</b>:</font> Haodong Duan, Nanxuan Zhao, Kai Chen, Dahua Lin  <br>
    <font color=Gray><b>· · Organization(s)</b>:</font>  The Chinese University of HongKong; Shanghai AI Laboratory; Centre of Perceptual and Interactive Intelligence; University of Bath; SenseTime Research <br>
    <font color=Gray><b>· · Description</b>: </font>  <br>
    <font color=Gray><b>· · Tags</b>: </font> Transformer
    </details>

## 2021

***
- VideoMoCo: Contrastive Video Representation Learning with
Temporally Adversarial Examples (**VideoMoCo** - <font color="#dd0000">**CVPR**21</font>) [[paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_VideoMoCo_Contrastive_Video_Representation_Learning_With_Temporally_Adversarial_Examples_CVPR_2021_paper.pdf) 
    <details> 
    <summary><font size=2>More Info</font></summary>
    <font color=Gray> <b>· · Author(s)</b>:</font> Tian Pan, Yibing Song, Tianyu Yang, Wenhao Jiang, Wei Liu  <br>
    <font color=Gray><b>· · Organization(s)</b>:</font> Tencent AI Lab; Tencent Data Platform <br>
    <font color=Gray><b>· · Description</b>: </font>  <br>
    <font color=Gray><b>· · Tags</b>: </font> 
    </details>

## 2020

***
- Video Playback Rate Perception for Self-Supervised Spatio-Temporal Representation Learning (**PRP** - <font color="#dd0000">**CVPR**20</font>) [[paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Yao_Video_Playback_Rate_Perception_for_Self-Supervised_Spatio-Temporal_Representation_Learning_CVPR_2020_paper.pdf) 
    <details> 
    <summary><font size=2>More Info</font></summary>
    <font color=Gray> <b>· · Author(s)</b>:</font> Yuan Yao, Chang Liu, Dezhao Luo, Yu Zhou, Qixiang Ye  <br>
    <font color=Gray><b>· · Organization(s)</b>:</font> UCAS; IIE, CAS <br>
    <font color=Gray><b>· · Description</b>: </font>  <br>
    <font color=Gray><b>· · Tags</b>: </font> Pretext Task
    </details>

***
- Video Cloze Procedure for Self-Supervised  Spatio-Temporal Learning (**VCP** - <font color="#dd0000">**AAAI**20 Oral</font>) [[paper]](https://ojs.aaai.org//index.php/AAAI/article/view/6840) 
    <details> 
    <summary><font size=2>More Info</font></summary>
    <font color=Gray> <b>· · Author(s)</b>:</font> Dezhao Luo, Chang Liu, Yu Zhou, Dongbao Yang, Can Ma, Qixiang Ye, Weiping Wang  <br>
    <font color=Gray><b>· · Organization(s)</b>:</font>  IIE, CAS; UCAS <br>
    <font color=Gray><b>· · Description</b>: </font>  <br>
    <font color=Gray><b>· · Tags</b>: </font> Pretext Task
    </details>

***
Thanks for the support of Prof. [Yu Zhou](https://people.ucas.ac.cn/~yuzhou).


